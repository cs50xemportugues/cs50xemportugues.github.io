Ordenação por intercalação
----------

* Podemos aplicar a ideia de recursão à ordenação, com um outro algoritmo chamado ordenação por intercalação. O pseudocódigo pode ser assim:

        Se tiver apenas um item
          Retorne
        Senão
            Ordenar a metade esquerda dos itens
            Ordenar a metade direita dos itens
            Intercalar as metades ordenadas
        
    
* Podemos entender melhor com uma lista não ordenada como exemplo:
    
        7 4 5 2 6 3 8 1
        
    
* Primeiramente, vamos ordenar a metade esquerda (os primeiros quatro elementos):
    
        7 4 5 2 | 6 3 8 1
        – – – –
        
    
* Para ordenar isso, precisamos primeiro ordenar a metade esquerda da metade esquerda:
    
        7 4 | 5 2 | 6 3 8 1
        – –
        
    
* Agora, temos apenas um item, `7`, na metade esquerda, e um item, `4`, na metade direita. Então, vamos intercalar os dois, pegando o item menor de cada lista primeiro:
    
        – – | 5 2 | 6 3 8 1
        4 7
        
    
* Agora voltamos para a metade direita da metade esquerda e a ordenamos:
    
        – – | – – | 6 3 8 1
        4 7 | 2 5
        
    
* Agora que ambas as metades da metade esquerda estão ordenadas, podemos intercalá-las. Olhamos para o início de cada lista e pegamos o `2` já que é menor que `4`. Em seguida, pegamos o `4` pois é o menor item do início de ambas as listas. Em seguida, pegamos o `5` e finalmente o `7`, dando-nos:
    
        – – – – | 6 3 8 1
        – – – –
        2 4 5 7
        
    
* Agora vamos ordenar a metade direita da mesma maneira. Primeiro, a metade esquerda da metade direita:
    
        – – – – | – – | 8 1
        – – – – | 3 6 |
        2 4 5 7
        
    
* Em seguida, a metade direita da metade direita:
    
        – – – – | – – | – –
        – – – – | 3 6 | 1 8
        2 4 5 7
        
    
* Podemos intercalar a metade direita agora:
    
        – – – – | – – – –
        – – – – | – – – –
        2 4 5 7 | 1 3 6 8
        
    
* Por fim, podemos intercalar ambas as metades da lista completa, seguindo os mesmos passos de antes. Observe que não precisamos verificar todos os elementos de cada metade para encontrar o menor, pois sabemos que cada metade já está ordenada. Em vez disso, pegamos o elemento menor das duas metades no início de cada uma:
    
        – – – – | – – – –
        – – – – | – – – –
        2 4 5 7 | – 3 6 8
        1
        
    
        – – – – | – – – –
        – – – – | – – – –
        – 4 5 7 | – 3 6 8
        1 2
        
    
        – – – – | – – – –
        – – – – | – – – –
        – 4 5 7 | – – 6 8
        1 2 3
        
    
        – – – – | – – – –
        – – – – | – – – –
        – – 5 7 | – – 6 8
        1 2 3 4
        
    
        – – – – | – – – –
        – – – – | – – – –
        – – – 7 | – – 6 8
        1 2 3 4   5
        
    
        – – – – | – – – –
        – – – – | – – – –
        – – – 7 | – – – 8
        1 2 3 4   5 6
        
    
        – – – – | – – – –
        – – – – | – – – –
        – – – – | – – – 8
        1 2 3 4   5 6 7
        
    
        – – – – | – – – –
        – – – – | – – – –
        – – – – | – – – –
        1 2 3 4   5 6 7 8
        
    
* Foram necessários diversos passos, mas na verdade foram menos passos do que nos outros algoritmos que vimos até agora. Dividimos nossa lista pela metade a cada vez, até estarmos "ordenando" oito listas com apenas um elemento cada:
    
        7 | 4 | 5 | 2 | 6 | 3 | 8 | 1
        4   7 | 2   5 | 3   6 | 1   8
        2   4   5   7 | 1   3   6   8
        1   2   3   4   5   6   7   8
        
    
* Como nosso algoritmo dividiu o problema pela metade a cada vez, seu tempo de execução é logarítmico com _O_(log _n_). E depois de ordenarmos cada metade (ou metade de uma metade), precisamos intercalar todos os elementos, com _n_ passos, já que precisamos olhar cada elemento uma vez.
* Portanto, nosso tempo de execução total é _O_(_n_ log _n_):
    * _O_(_n_2)
        * ordenação bolha (bubble sort), ordenação por seleção (selection sort)
    * _O_(_n_ log _n_)
        * ordenação por intercalação (merge sort)
    * _O_(_n_)
        * busca linear (linear search)
    * _O_(log _n_)
        * busca binária (binary search)
    * _O_(1)
* Como log _n_ é maior que 1, mas menor que _n_, _n_ log _n_ está entre _n_ (vezes 1) e _n_2.
* O melhor caso, Ω, ainda é _n_ log _n_, pois ainda ordenamos cada metade primeiro e depois as intercalamos:
    * Ω(_n_2)
        * ordenação por seleção (selection sort)
    * Ω(_n_ log _n_)
        * ordenação por intercalação (merge sort)
    * Ω(_n_)
        * ordenação bolha (bubble sort)
    * Ω(log _n_)
    * Ω(1)
        * busca linear (linear search), busca binária (binary search)
* Finalmente, há outra notação, Θ, Theta, que usamos para descrever os tempos de execução dos algoritmos se o limite superior e o limite inferior forem os mesmos. Por exemplo, a ordenação por intercalação tem Θ(_n_ log _n_), já que o melhor e o pior caso requerem o mesmo número de passos. E a ordenação por seleção tem Θ(_n_2).
* Podemos ver uma [visualização final](https://www.youtube.com/watch?v=ZZuD6iUe3Pc) dos algoritmos de ordenação com um maior número de entradas, executando ao mesmo tempo.