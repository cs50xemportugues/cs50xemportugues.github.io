
Memory, imprecision, and overflow
=================================

*   Our computer has memory, in hardware chips called RAM, random-access memory. Our programs use that RAM to store data as they run, but that memory is finite. So with a finite number of bits, we can’t represent all possible numbers (of which there are an infinite number of). So our computer has a certain number of bits for each float and int, and has to round to the nearest decimal value at a certain point.
*   With `floats.c`, we can see what happens when we use floats:
    
        #include <cs50.h>
        #include <stdio.h>
        
        int main(void)
        {
            // Prompt user for x
            float x = get_float("x: ");
        
            // Prompt user for y
            float y = get_float("y: ");
        
            // Perform division
            printf("x / y = %.50f\n", x / y);
        }
        
    
    *   With `%50f`, we can specify the number of decimal places displayed.
    *   Hmm, now we get …
        
            x: 1
            y: 10
            x / y = 0.10000000149011611938476562500000000000000000000000
            
        
    *   It turns out that this is called **floating-point imprecision**, where we don’t have enough bits to store all possible values, so the computer has to store the closest value it can to 1 divided by 10.
*   We can see a similar problem in `overflow.c`:
    
        #include <stdio.h>
        #include <unistd.h>
        
        int main(void)
        {
            for (int i = 1; ; i *= 2)
            {
                printf("%i\n", i);
                sleep(1);
            }
        }
        
    
    *   In our `for` loop, we set `i` to `1`, and double it with `*= 2`. (And we’ll keep doing this forever, so there’s no condition we check.)
    *   We also use the `sleep` function from `unistd.h` to let our program pause each time.
    *   Now, when we run this program, we see the number getting bigger and bigger, until:
        
            1073741824
            overflow.c:6:25: runtime error: signed integer overflow: 1073741824 * 2 cannot be represented in type 'int'
            -2147483648
            0
            0
            ...
            
        
    *   It turns out, our program recognized that a signed integer (an integer with a positive or negative sign) couldn’t store that next value, and printed an error. Then, since it tried to double it anyways, `i` became a negative number, and then 0.
    *   This problem is called **integer overflow**, where an integer can only be so big before it runs out of bits and “rolls over”. We can picture adding 1 to 999 in decimal. The last digit becomes 0, we carry the 1 so the next digit becomes 0, and we get 1000. But if we only had three digits, we would end up with 000 since there’s no place to put the final 1!
*   The Y2K problem arose because many programs stored the calendar year with just two digits, like 98 for 1998, and 99 for 1999. But when the year 2000 approached, the programs would have stored 00, leading to confusion between the years 1900 and 2000.
*   A Boeing 787 airplane also had a bug where a counter in the generator overflows after a certain number of days of continuous operation, since the number of seconds it has been running could no longer be stored in that counter.
*   So, we’ve seen a few problems that can happen, but now understand why, and how to prevent them.
*   With this week’s problem set, we’ll use the CS50 Lab, built on top of the CS50 Sandbox, to write some programs with walkthroughs to guide us.