
IMDb
----

*   IMDb, or “Internet Movie Database”, has datasets [available to download](https://www.imdb.com/interfaces/) as TSV, or tab-separate values, files.
*   For example, we can download `title.basics.tsv.gz`, which will contain basic data about titles:
    *   `tconst`, a unique identifier for each title, like `tt4786824`
    *   `titleType`, the type of the title, like `tvSeries`
    *   `primaryTitle`, the main title used, like `The Crown`
    *   `startYear`, the year a title was released, like `2016`
    *   `genres`, a comma-separated list of genres, like `Drama,History`
*   We take a look at `title.basics.tsv` after we’ve unzipped it, and we see that the first rows are indeed the headers we expected and each row has values separated by tabs. But the file has more than 6 million rows, so even searching for one value takes a moment.
*   We’ll download the file into our IDE with `wget`, and then `gunzip` to unzip it. But our IDE doesn’t have enough space, so we’ll use our Mac’s terminal instead.
*   We’ll write `import.py` to read the file in:
    
        import csv
        
        # Open TSV file for reading
        with open("title.basics.tsv", "r") as titles:
        
            # Since the file is a TSV file, we can use the CSV reader and change
            # the separator to a tab.
            reader = csv.DictReader(titles, delimiter="\t")
        
            # Open new CSV file for writing
            with open("shows0.csv", "w") as shows:
        
                # Create writer
                writer = csv.writer(shows)
        
                # Write header of the columns we want
                writer.writerow(["tconst", "primaryTitle", "startYear", "genres"])
        
                # Iterate over TSV file
                for row in reader:
        
                    # If non-adult TV show
                    if row["titleType"] == "tvSeries" and row["isAdult"] == "0":
        
                        # Write row
                        writer.writerow([row["tconst"], row["primaryTitle"], row["startYear"], row["genres"]])
        
    
*   Now, we can open `shows0.csv` and see a smaller set of data. But it turns out, for some of the rows, `startYear` has a value of `\N`, and that’s a special value from IMDb when they want to represent values that are missing. So we can filter out those values and convert the `startYear` to an integer to filter for shows after 1970:
    
        ...
        # If year not missing (We need to escape the backslash too)
        if row["startYear"] != "\\N":
        
            # If since 1970
            if int(row["startYear"]) >= 1970:
        
                # Write row
                writer.writerow([row["tconst"], row["primaryTitle"], row["startYear"], row["genres"]])
        
    
*   We can write a program to search for a particular title:
    
        import csv
        
        # Prompt user for title
        title = input("Title: ")
        
        # Open CSV file
        with open("shows2.csv", "r") as input:
        
            # Create DictReader
            reader = csv.DictReader(input)
        
            # Iterate over CSV file
            for row in reader:
        
                # Search for title
                if title.lower() == row["primaryTitle"].lower():
                    print(row["primaryTitle"], row["startYear"], row["genres"], sep=" | ")
        
    
    *   We can run this program and see our results, but we can see how SQL can do a better job.
*   In Python, we can connect to a SQL database and read our file into it once, so we can make lots of queries without writing new programs and without having to read the entire file each time.
*   Let’s do this more easily with the CS50 library:
    
        import cs50
        import csv
        
        # Create database by opening and closing an empty file first
        open(f"shows3.db", "w").close()
        db = cs50.SQL("sqlite:///shows3.db")
        
        # Create table called `shows`, and specify the columns we want,
        # all of which will be text except `startYear`
        db.execute("CREATE TABLE shows (tconst TEXT, primaryTitle TEXT, startYear NUMERIC, genres TEXT)")
        
        # Open TSV file
        # https://datasets.imdbws.com/title.basics.tsv.gz
        with open("title.basics.tsv", "r") as titles:
        
            # Create DictReader
            reader = csv.DictReader(titles, delimiter="\t")
        
            # Iterate over TSV file
            for row in reader:
        
                # If non-adult TV show
                if row["titleType"] == "tvSeries" and row["isAdult"] == "0":
        
                    # If year not missing
                    if row["startYear"] != "\\N":
        
                        # If since 1970
                        startYear = int(row["startYear"])
                        if startYear >= 1970:
        
                            # Insert show by substituting values into each ? placeholder
                            db.execute("INSERT INTO shows (tconst, primaryTitle, startYear, genres) VALUES(?, ?, ?, ?)",
                                       row["tconst"], row["primaryTitle"], startYear, genres)
        
    
*   Now we can run `sqlite3 shows3.db` and run commands like before, such as `SELECT * FROM shows LIMIT 10;`.
*   With `SELECT COUNT(*) FROM shows;` we can see that there are more than 150,000 shows in our table, and with `SELECT COUNT(*) FROM shows WHERE startYear = 2019;`, we see that there were more than 6000 this year.
